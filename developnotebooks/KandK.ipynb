{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import opt_einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "hparams = {}\n",
    "hparams['N_layers'] = 1\n",
    "hparams['N'] = 16\n",
    "hparams['k'] = 16\n",
    "params['hparams'] = hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99990001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "n**2 - (n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KandK(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.hparams = params['hparams']\n",
    "        self.init_layers()\n",
    "        \n",
    "    def init_layers(self):\n",
    "        self.layers1 = nn.ModuleList()\n",
    "        #Layers\n",
    "        for i in range(self.hparams['N_c']):\n",
    "            self.layers1.append(nn.Linear(in_features=int(self.hparams['N']), out_features=int(self.hparams['k']), bias=True))\n",
    "            self.layers1.append(nn.Linear(in_features=int(self.hparams['k']), out_features=int(self.hparams['k']), bias=False)) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        F = x\n",
    "        F_i = x\n",
    "        lnabsTrF_i = torch.zeros((x.shape[0],self.hparams['N']))#, dtype=self.hparams['dtype'], device=self.device)\n",
    "        TrF_i = opt_einsum.contract('nii->n', F_i)\n",
    "        lnabsTrF_i[:,0] = torch.log(torch.abs(TrF_i))\n",
    "        for i in range(1,self.hparams['N']):\n",
    "            F_i = torch.matmul(F,F_i)\n",
    "            TrF_i = opt_einsum.contract('nii->n', F_i)\n",
    "            lnabsTrF_i[:,i] = torch.log(torch.abs(TrF_i))\n",
    "        c = torch.zeros(x.shape[0],self.hparams['k'])#, dtype=self.hparams['dtype'], device=self.device)\n",
    "        for i in range(0, len(self.layers1), 2):\n",
    "            c_i = torch.exp(self.layers1[i](lnabsTrF_i))\n",
    "            c_i = self.layers1[i+1](c_i)\n",
    "            c += c_i\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,hparams['N'],hparams['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KandK(\n",
       "  (layers1): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=16, bias=False)\n",
       "  )\n",
       "  (layers2): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=100, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=100, out_features=16, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KandK(params)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 809308.3125, -282580.1250,   53416.7109,   -2056.7617, -105692.1562,\n",
       "           83103.6406,  438222.8125, -596302.1250, -372350.1562, -414877.4062,\n",
       "          966563.8750,   15350.7451,  558314.5625,  378550.8125, -489255.7500,\n",
       "         -300074.0938]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33728"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(100,hparams['N'],hparams['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(x, dim=(-1,-2), p='fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
