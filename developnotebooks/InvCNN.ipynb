{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23fc94e9-3502-4bf8-b4b6-67d916d56a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../ml')\n",
    "from customlayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64612148-4611-4663-9114-0c2081b42e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a3348d8-1ced-4e37-a51f-c8c8cde3aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "hparams = {}\n",
    "\n",
    "#Training data\n",
    "hparams['N_samples'] = 10000\n",
    "hparams['d'] = 2\n",
    "hparams['l_min'] = 0.5\n",
    "hparams['l_max'] = 1\n",
    "\n",
    "#Training settings\n",
    "hparams['dtype'] = torch.float64\n",
    "hparams['precision'] = 64\n",
    "hparams['devices'] = [0]\n",
    "hparams['matrix_loss'] = None #relativefrobeniusnorm\n",
    "hparams['optimizer1'] = torch.optim.Adam\n",
    "hparams['optimizer2'] = torch.optim.LBFGS\n",
    "hparams['switch_threshold'] = 5e-3\n",
    "hparams['learning_rate'] = 1e-3\n",
    "hparams['batch_size'] = 100\n",
    "hparams['epochs'] = 5000\n",
    "\n",
    "#System net\n",
    "hparams['modeltype'] = 'NGO'\n",
    "hparams['model/data'] = 'model'\n",
    "hparams['gamma_stabilization'] = 0\n",
    "hparams['kernel_sizes'] = [5,5,2,2,2,2,5,5]\n",
    "hparams['N_w'] = 30000\n",
    "hparams['bottleneck_size'] = 20\n",
    "hparams['NLB_outputactivation'] = nn.Tanhshrink()\n",
    "hparams['bias_NLBranch'] = False\n",
    "hparams['bias_LBranch'] = False\n",
    "\n",
    "#Bases\n",
    "hparams['h'] = [10,10]\n",
    "hparams['p'] = 3\n",
    "hparams['C'] = 2\n",
    "hparams['N'] = np.prod(hparams['h'])\n",
    "\n",
    "#Quadrature\n",
    "hparams['quadrature'] = 'Gauss-Legendre'\n",
    "hparams['n_elements'] = max(int((hparams['h'][0] - 1)/hparams['p']), 1)\n",
    "hparams['Q'] = 33*hparams['n_elements']\n",
    "\n",
    "hparams['quadrature_L'] = 'Gauss-Legendre'\n",
    "hparams['n_elements_L'] = max(int((hparams['h'][0] - 1)/hparams['p']), 1)\n",
    "hparams['Q_L'] = 33*hparams['n_elements_L']\n",
    "\n",
    "#Symmetries\n",
    "hparams['scaling_equivariance'] = False\n",
    "hparams['permutation_equivariance'] = False\n",
    "\n",
    "params['hparams'] = hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0322e7fd-0d15-4cb4-8b4d-24fc77fe75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvCNN(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.hparams = params['hparams']\n",
    "        #Balancing the number of trainable parameters to N_w\n",
    "        self.num_channels = 1\n",
    "        count = 0\n",
    "        num_channels_list = []\n",
    "        while count < self.hparams['N_w']:\n",
    "            self.init_layers()\n",
    "            count = sum(p.numel() for p in self.parameters())\n",
    "            num_channels_list.append(self.num_channels)\n",
    "            self.num_channels +=1\n",
    "        self.num_channels = num_channels_list[-2]\n",
    "        self.init_layers()\n",
    "        \n",
    "    def init_layers(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.kernel_sizes = self.hparams['kernel_sizes']\n",
    "        self.bottleneck_size = self.hparams['bottleneck_size']\n",
    "        #Layers\n",
    "        self.layers.append(ReshapeLayer(output_shape=(1,self.hparams['h'][0],self.hparams['h'][1])) if self.hparams['model/data']=='data' else ReshapeLayer(output_shape=(1,self.hparams['N'],self.hparams['N'])))\n",
    "        self.layers.append(nn.Conv2d(in_channels=1, out_channels=self.num_channels, kernel_size=self.kernel_sizes[0], stride=self.kernel_sizes[0], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Conv2d(in_channels=self.num_channels, out_channels=self.num_channels, kernel_size=self.kernel_sizes[1], stride=self.kernel_sizes[1], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Conv2d(in_channels=self.num_channels, out_channels=self.num_channels, kernel_size=self.kernel_sizes[2], stride=self.kernel_sizes[2], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Conv2d(in_channels=self.num_channels, out_channels=self.bottleneck_size, kernel_size=self.kernel_sizes[3], stride=self.kernel_sizes[3], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        # self.layers.append(ReshapeLayer(output_shape=(int(self.bottleneck_size),)))\n",
    "        self.layers.append(InversionLayer())\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        # self.layers.append(ReshapeLayer(output_shape=(self.bottleneck_size,1,1)))\n",
    "        self.layers.append(nn.ConvTranspose2d(self.bottleneck_size, self.num_channels, kernel_size=self.kernel_sizes[4], stride=self.kernel_sizes[4], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(self.num_channels, self.num_channels, kernel_size=self.kernel_sizes[5], stride=self.kernel_sizes[5], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(self.num_channels, self.num_channels, kernel_size=self.kernel_sizes[6], stride=self.kernel_sizes[6], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(self.num_channels, 1, kernel_size=self.kernel_sizes[7], stride=self.kernel_sizes[7], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(ReshapeLayer(output_shape=(self.hparams['N'],self.hparams['N'])))\n",
    "        if self.hparams['NLB_outputactivation'] is not None:\n",
    "            self.layers.append(self.hparams['NLB_outputactivation'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.hparams.get('permutation_equivariance',False)==True:\n",
    "            x, row_sorted_indices, col_sorted_indices = sort_matrices(x)\n",
    "        if self.hparams.get('scaling_equivariance',False)==True:\n",
    "            x_norm = torch.amax(torch.abs(x), dim=(-1,-2))\n",
    "            x = x/x_norm[:,None,None]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        y = x\n",
    "        if self.hparams.get('scaling_equivariance',False)==True:\n",
    "            y = y/x_norm[:,None,None]    \n",
    "        if self.hparams.get('permutation_equivariance',False)==True:\n",
    "            y = unsort_matrices(y, row_sorted_indices, col_sorted_indices)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrelongationCNN(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.hparams = params['hparams']\n",
    "        #Balancing the number of trainable parameters to N_w\n",
    "        self.num_channels = 1\n",
    "        count = 0\n",
    "        num_channels_list = []\n",
    "        while count < self.hparams['N_w']:\n",
    "            self.init_layers()\n",
    "            count = sum(p.numel() for p in self.parameters())\n",
    "            num_channels_list.append(self.num_channels)\n",
    "            self.num_channels +=1\n",
    "        self.num_channels = num_channels_list[-2]\n",
    "        self.init_layers()\n",
    "        \n",
    "    def init_layers(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.kernel_sizes = self.hparams['kernel_sizes']\n",
    "        self.bottleneck_size = self.hparams['bottleneck_size']\n",
    "        #Layers\n",
    "        self.layers.append(ReshapeLayer(output_shape=(1,self.hparams['h_F'][0],self.hparams['h_F'][1])) if self.hparams['model/data']=='data' else ReshapeLayer(output_shape=(1,self.hparams['N_F'],self.hparams['N_F'])))\n",
    "        self.layers.append(nn.ConvTranspose2d(1, self.num_channels, kernel_size=self.kernel_sizes[4], stride=self.kernel_sizes[4], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(self.num_channels, self.num_channels, kernel_size=self.kernel_sizes[5], stride=self.kernel_sizes[5], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(self.num_channels, self.num_channels, kernel_size=self.kernel_sizes[6], stride=self.kernel_sizes[6], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(self.num_channels, 1, kernel_size=self.kernel_sizes[7], stride=self.kernel_sizes[7], bias=self.hparams.get('bias_NLBranch', True)))\n",
    "        self.layers.append(ReshapeLayer(output_shape=(self.hparams['N'],self.hparams['N'])))\n",
    "        if self.hparams['NLB_outputactivation'] is not None:\n",
    "            self.layers.append(self.hparams['NLB_outputactivation'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.hparams.get('permutation_equivariance',False)==True:\n",
    "            x, row_sorted_indices, col_sorted_indices = sort_matrices(x)\n",
    "        if self.hparams.get('scaling_equivariance',False)==True:\n",
    "            x_norm = torch.amax(torch.abs(x), dim=(-1,-2))\n",
    "            x = x/x_norm[:,None,None]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        y = x\n",
    "        if self.hparams.get('scaling_equivariance',False)==True:\n",
    "            y = y/x_norm[:,None,None]    \n",
    "        if self.hparams.get('permutation_equivariance',False)==True:\n",
    "            y = unsort_matrices(y, row_sorted_indices, col_sorted_indices)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a459436-64a6-496f-9306-c49a146e4c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 100])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(hparams['batch_size'],hparams['N'],hparams['N'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58ddae4e-8ddb-4a1b-acc8-5cd98e14db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InvCNN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6439bf3c-7c3a-4315-b709-b1bdeb9f6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29988"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dddf0da3-0cb8-49fe-b5e6-9d2a0b9816ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.4900e-03,  1.2789e-04, -4.3645e-04,  ...,  1.2737e-02,\n",
       "          -1.5404e-06,  1.3446e-02],\n",
       "         [ 4.7337e-04,  1.6133e-04, -8.3207e-04,  ...,  3.7509e-03,\n",
       "           1.8909e-01,  7.3698e-04],\n",
       "         [ 1.7584e-04,  1.0041e-02,  9.7789e-06,  ...,  2.2210e-01,\n",
       "           6.4823e-03, -6.4596e-04],\n",
       "         ...,\n",
       "         [-1.6802e-03,  4.8157e-02,  6.0311e-03,  ...,  1.7680e-04,\n",
       "           5.7013e-02, -1.8016e-02],\n",
       "         [-3.9019e-05, -8.8141e-03, -3.3028e-05,  ...,  5.7068e-05,\n",
       "           8.9847e-02,  1.1832e-02],\n",
       "         [-4.0374e-04, -2.7474e-08,  1.1369e-02,  ..., -1.9241e-05,\n",
       "          -3.3357e-02, -3.0098e-02]],\n",
       "\n",
       "        [[-2.1715e-04, -2.2836e-05, -2.8033e-06,  ...,  9.9324e-04,\n",
       "           4.4893e-05,  1.1036e-07],\n",
       "         [ 0.0000e+00,  2.6911e-05, -6.3397e-05,  ...,  1.3068e-04,\n",
       "           4.8744e-03,  5.7295e-06],\n",
       "         [-1.0477e-09,  8.4996e-04,  4.4085e-05,  ...,  5.8231e-03,\n",
       "           1.0273e-04,  2.5611e-09],\n",
       "         ...,\n",
       "         [-6.0722e-07,  7.4774e-05,  9.8925e-06,  ..., -1.7462e-10,\n",
       "           3.4287e-04, -4.0904e-05],\n",
       "         [-4.6100e-05, -1.4063e-07,  1.7464e-05,  ...,  3.5642e-04,\n",
       "           3.2596e-09,  4.3903e-05],\n",
       "         [ 5.5239e-05,  1.2375e-05,  8.8476e-09,  ..., -4.8894e-09,\n",
       "           2.2119e-09, -1.2542e-04]],\n",
       "\n",
       "        [[-8.4989e-05,  6.6966e-05, -3.4023e-05,  ...,  6.8583e-04,\n",
       "           9.4563e-05,  1.0226e-05],\n",
       "         [-3.9395e-07,  6.2399e-08, -7.8045e-07,  ...,  7.8605e-04,\n",
       "           6.1936e-03,  1.8477e-06],\n",
       "         [-6.8098e-06,  1.3013e-03,  1.6637e-05,  ...,  4.5453e-03,\n",
       "           3.2089e-04,  1.5453e-05],\n",
       "         ...,\n",
       "         [-2.4159e-05,  4.5903e-04,  1.6555e-05,  ...,  1.7971e-05,\n",
       "           3.7920e-04, -1.4260e-05],\n",
       "         [-1.3807e-04, -5.3123e-06,  9.1165e-05,  ...,  5.2984e-04,\n",
       "           1.7028e-04,  7.9516e-06],\n",
       "         [ 6.6128e-05,  8.7924e-05,  1.1642e-10,  ..., -1.2409e-05,\n",
       "          -4.0513e-04, -2.4829e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.4108e-03, -3.7057e-03, -1.2571e-03,  ...,  2.9649e-03,\n",
       "          -3.5409e-05,  4.3530e-06],\n",
       "         [ 9.1836e-05,  1.2006e-03, -1.4898e-04,  ...,  2.6085e-03,\n",
       "           1.9892e-02,  7.1354e-04],\n",
       "         [-4.7369e-04,  1.9377e-02,  4.4253e-04,  ...,  1.2190e-02,\n",
       "           3.2163e-04,  1.3248e-03],\n",
       "         ...,\n",
       "         [-7.6956e-04,  5.9356e-03,  1.2741e-03,  ...,  1.1860e-03,\n",
       "           1.6220e-03,  1.7462e-10],\n",
       "         [-1.0416e-04, -8.3819e-09,  4.4467e-04,  ...,  1.3434e-03,\n",
       "           4.0875e-04,  8.5074e-04],\n",
       "         [ 1.6676e-03,  8.2390e-04,  1.7965e-04,  ..., -6.9126e-05,\n",
       "          -5.5812e-04,  1.8626e-09]],\n",
       "\n",
       "        [[-1.8510e-02, -2.9698e-03, -1.1041e-02,  ...,  9.6374e-03,\n",
       "           8.3819e-09,  2.4579e-05],\n",
       "         [ 4.2032e-03,  5.2530e-03, -3.3615e-04,  ...,  2.3283e-10,\n",
       "           4.4119e-02,  7.3314e-05],\n",
       "         [-3.1057e-04,  7.1428e-02,  3.3166e-04,  ...,  1.0376e-02,\n",
       "           5.2930e-04,  4.3445e-03],\n",
       "         ...,\n",
       "         [-1.1381e-05,  9.7586e-04,  1.0575e-03,  ...,  2.1144e-03,\n",
       "           8.5317e-05, -6.0629e-07],\n",
       "         [ 9.9279e-07, -7.3686e-06,  2.2162e-05,  ...,  1.9335e-03,\n",
       "           8.6737e-04,  1.9862e-03],\n",
       "         [ 1.0169e-04, -3.8493e-05,  5.4073e-06,  ..., -3.3532e-04,\n",
       "           4.0084e-06,  1.0206e-03]],\n",
       "\n",
       "        [[-7.9337e-04,  1.7919e-04, -2.3283e-09,  ...,  1.2200e-07,\n",
       "           1.7462e-10, -7.4048e-05],\n",
       "         [-2.7013e-04, -6.1523e-05,  1.9260e-05,  ...,  1.9909e-03,\n",
       "           5.1487e-03,  1.9034e-03],\n",
       "         [-7.4692e-07,  6.2735e-03,  3.9682e-04,  ...,  3.8703e-03,\n",
       "           1.0372e-04,  2.0124e-04],\n",
       "         ...,\n",
       "         [ 5.8208e-10,  6.0609e-04,  4.8421e-05,  ...,  5.1793e-04,\n",
       "           6.6856e-03, -5.0176e-05],\n",
       "         [-2.7746e-05, -6.9108e-05,  1.0976e-03,  ...,  2.1370e-02,\n",
       "          -3.2897e-04,  2.6509e-04],\n",
       "         [ 1.4818e-03,  2.9634e-04,  3.2157e-05,  ...,  1.4760e-04,\n",
       "          -1.0721e-04, -2.7288e-07]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4c69a-456b-4aae-a452-d40af598e38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
